{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714dd8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('.', '..')))\n",
    "sys.path.append(os.path.abspath(os.path.join('.', 'utils')))\n",
    "\n",
    "# import utils.str_manip as str_manip\n",
    "# import utils.feature_builder as feature_builder\n",
    "import utils.cluster as cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f63729",
   "metadata": {},
   "source": [
    "## Load the original data and extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4755316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing clusters\n",
    "orig_df = pd.read_csv('../data/original_clusters.csv')\n",
    "# keep only first 2 columns\n",
    "orig_df = orig_df[['Title', 'Cluster']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461cde54",
   "metadata": {},
   "source": [
    "### We can use other classes to perform low-level functionality directly (for testing purposes, etc.), but the Cluster class is already subclassed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = str_manip.StrManip()\n",
    "# fb = feature_builder.FeatureBuilder()\n",
    "cl = cluster.Cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae623679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in the raw data to get out features\n",
    "feats = cl.get_features(orig_df['Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f78855",
   "metadata": {},
   "source": [
    "## Create the processing pipeline\n",
    "### Configurations for all possible combinations of the processing pipeline\n",
    "The kwargs for clustering algorithms are algorithm specific.\n",
    "Outer arguments are used for \"global\" variables and pipeline building:\n",
    "- scaler: choose which scaling factor to use, or None\n",
    "- dim_reduce: choose which dimensionality reduction algorithm to use, or None\n",
    "- clusterer: choose which clustering algorithm to use.\n",
    "- n_clusters: the number of clusters to aim for during clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_config = {\n",
    "    \"kmeans_kwargs\": {\n",
    "        \"init\": \"k-means++\",\n",
    "        \"n_init\": 50,\n",
    "        \"max_iter\": 500,\n",
    "        \"random_state\": 2901,\n",
    "    },\n",
    "    \"hdbscan_kwargs\": {\n",
    "        'min_cluster_size': 15,\n",
    "        'min_samples': 10,\n",
    "        'metric': 'euclidean',\n",
    "    },\n",
    "    \"agglom_kwargs\": {\n",
    "        'metric': 'euclidean',\n",
    "        'linkage': 'ward',\n",
    "    },\n",
    "    \"cluster\": \"kmeans\", # kmeans, hdbscan, agglom\n",
    "    \"scaler\": \"minmax\", # std, minmax\n",
    "    \"dim_reduce\": \"pca\", # pca, umap\n",
    "    \"n_clusters\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb854376",
   "metadata": {},
   "source": [
    "### See how the data is grouped after dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33e0605",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_red = cluster.Cluster()\n",
    "cluster_config['dim_reduce'] = 'pca'\n",
    "pipe = dim_red.setup_pipeline(**cluster_config)\n",
    "pipe.fit(feats)\n",
    "df = dim_red.run_pipeline(pipe, feats, orig_df['Cluster'])\n",
    "dim_red.show_simple_scatterplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c68885a",
   "metadata": {},
   "source": [
    "The above graph shows that PCA has grouped data into dense clusters of varying shapes. HDBSCAN would be a good candidate clustering algorithm for this dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a981488",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_red = cluster.Cluster()\n",
    "cluster_config['dim_reduce'] = 'umap'\n",
    "pipe = dim_red.setup_pipeline(**cluster_config)\n",
    "pipe.fit(feats)\n",
    "df = dim_red.run_pipeline(pipe, feats, orig_df['Cluster'])\n",
    "dim_red.show_simple_scatterplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62710ae1",
   "metadata": {},
   "source": [
    "The above graph shows that UMAP has grouped data into more convex-looking clusters. k-means would be a good candidate clustering algorithm for this dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c138a7",
   "metadata": {},
   "source": [
    "### Run grid search to find the best values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba28ba0",
   "metadata": {},
   "source": [
    "Running for k-means..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d227d185",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_config['cluster'] = 'kmeans'\n",
    "cluster_config['dim_reduce'] = 'umap'\n",
    "cl.find_best_n_components(feats, orig_df['Cluster'], cluster_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db1b1a3",
   "metadata": {},
   "source": [
    "Looks like the best value for n_components could be 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced78158",
   "metadata": {},
   "source": [
    "Running for HDBSCAN..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de081db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_config['cluster'] = 'hdbscan'\n",
    "cluster_config['dim_reduce'] = 'pca'\n",
    "cl.find_best_n_components(feats, orig_df['Cluster'], cluster_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d46972",
   "metadata": {},
   "source": [
    "Looks like the best value for n_components is 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e9b187",
   "metadata": {},
   "source": [
    "### Choose a clustering algorithm and set up the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cefb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset some variables\n",
    "cl.n_components = 2\n",
    "cl.component_columns = ['component_1', 'component_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab77af4",
   "metadata": {},
   "source": [
    "We start with k-means + UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b3b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_config['cluster'] = 'kmeans'\n",
    "cluster_config['dim_reduce'] = 'umap'\n",
    "cluster_config['n_clusters'] = 7\n",
    "pipe = cl.setup_pipeline(**cluster_config)\n",
    "pipe[\"dim_reducer\"][cluster_config['dim_reduce']].n_components = 2\n",
    "\n",
    "pipe.fit(feats)\n",
    "\n",
    "df = cl.run_pipeline(pipe, feats, orig_df['Cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4747284d",
   "metadata": {},
   "source": [
    "### Use the best values to create clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55241537",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.show_scatterplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9527253",
   "metadata": {},
   "source": [
    "Now we do the same for HDBSCAN + PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160caf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_config['cluster'] = 'hdbscan'\n",
    "cluster_config['dim_reduce'] = 'pca'\n",
    "cluster_config['n_clusters'] = 5\n",
    "pipe = cl.setup_pipeline(**cluster_config)\n",
    "pipe[\"dim_reducer\"][cluster_config['dim_reduce']].n_components = 2\n",
    "\n",
    "pipe.fit(feats)\n",
    "\n",
    "df = cl.run_pipeline(pipe, feats, orig_df['Cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.show_scatterplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f298b8",
   "metadata": {},
   "source": [
    "## Analyze the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3674b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze predicted groups\n",
    "mask = df[df['predicted_cluster']==3].reset_index()['index']\n",
    "# orig_df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1684327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.topic_analysis(orig_df['Title'], feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c01e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
